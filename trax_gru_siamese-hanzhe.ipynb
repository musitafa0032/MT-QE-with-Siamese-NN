{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2792a68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "#import trax #google neuralnetwork builder now can only be implemented in ios or linux\n",
    "#from trax import layers as tl\n",
    "#from trax.supervised import training\n",
    "#from trax.fastmath import numpy as fastnp #make np calculate faster\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import jieba #Chinese character segmentation tools\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3853438",
   "metadata": {},
   "source": [
    "# Preprocessing the data and creating the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89a804f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sents for total:  100000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent1</th>\n",
       "      <th>sent2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>用微信都6年，微信没有微粒贷功能</td>\n",
       "      <td>4。  号码来微粒贷</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>微信消费算吗</td>\n",
       "      <td>还有多少钱没还</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>交易密码忘记了找回密码绑定的手机卡也掉了</td>\n",
       "      <td>怎么最近安全老是要改密码呢好麻烦</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>你好 我昨天晚上申请的没有打电话给我 今天之内一定会打吗？</td>\n",
       "      <td>什么时候可以到账</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“微粒贷开通\"</td>\n",
       "      <td>你好，我的微粒贷怎么没有开通呢</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>为什么借款后一直没有给我回拨电话</td>\n",
       "      <td>怎么申请借款后没有打电话过来呢！</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>为什么我每次都提前还款了最后却不给我贷款了</td>\n",
       "      <td>30号我一次性还清可以不</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>请问一天是否都是限定只能转入或转出都是五万。</td>\n",
       "      <td>微众多少可以赎回短期理财</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>微粒咨询电话号码多少</td>\n",
       "      <td>你们的人工客服电话是多少</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>已经在银行换了新预留号码。</td>\n",
       "      <td>我现在换了电话号码，这个需要更换吗</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           sent1              sent2  is_duplicate\n",
       "0               用微信都6年，微信没有微粒贷功能         4。  号码来微粒贷             0\n",
       "1                         微信消费算吗            还有多少钱没还             0\n",
       "2           交易密码忘记了找回密码绑定的手机卡也掉了   怎么最近安全老是要改密码呢好麻烦             0\n",
       "3  你好 我昨天晚上申请的没有打电话给我 今天之内一定会打吗？           什么时候可以到账             0\n",
       "4                        “微粒贷开通\"    你好，我的微粒贷怎么没有开通呢             0\n",
       "5               为什么借款后一直没有给我回拨电话   怎么申请借款后没有打电话过来呢！             1\n",
       "6          为什么我每次都提前还款了最后却不给我贷款了       30号我一次性还清可以不             0\n",
       "7         请问一天是否都是限定只能转入或转出都是五万。       微众多少可以赎回短期理财             0\n",
       "8                     微粒咨询电话号码多少       你们的人工客服电话是多少             1\n",
       "9                  已经在银行换了新预留号码。  我现在换了电话号码，这个需要更换吗             1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"train.txt\",sep='\\\\t',header=None,engine=\"python\",names=[\"sent1\",\"sent2\",\"is_duplicate\"])\n",
    "n_len=len(data)\n",
    "print('Number of sents for total: ', n_len)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b52b1a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data_train: 90000 Data_test: 10000\n"
     ]
    }
   ],
   "source": [
    "#slit dataframe data\n",
    "data_train = data.sample(frac=0.9,random_state=0,axis=0) # make my each random sample same\n",
    "data_test  = data[~data.index.isin(data_train.index)]\n",
    "data_train[\"sent1+sent2\"]=data_train[\"sent1\"]+data_train[\"sent2\"]\n",
    "print(\"Data_train:\", len(data_train), \"Data_test:\", len(data_test))\n",
    "del(data) # free the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "03ee4238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent1</th>\n",
       "      <th>sent2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>sent1+sent2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3582</th>\n",
       "      <td>何时可以受邀？</td>\n",
       "      <td>何时会激请我？</td>\n",
       "      <td>1</td>\n",
       "      <td>何时可以受邀？何时会激请我？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60498</th>\n",
       "      <td>如何更改还款卡号？</td>\n",
       "      <td>如何更换还款联系电话</td>\n",
       "      <td>0</td>\n",
       "      <td>如何更改还款卡号？如何更换还款联系电话</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53227</th>\n",
       "      <td>23号凌晨没存进去，白天存进去算逾期吗</td>\n",
       "      <td>。我今天早上还款算逾期吗？今天凌晨到期我晕</td>\n",
       "      <td>1</td>\n",
       "      <td>23号凌晨没存进去，白天存进去算逾期吗。我今天早上还款算逾期吗？今天凌晨到期我晕</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21333</th>\n",
       "      <td>如何查看合同</td>\n",
       "      <td>可以帮我看一下合同真假吗</td>\n",
       "      <td>0</td>\n",
       "      <td>如何查看合同可以帮我看一下合同真假吗</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3885</th>\n",
       "      <td>为什么我还款了不能再借？我每次还款都没预期啊</td>\n",
       "      <td>提前还款为何不能再借了</td>\n",
       "      <td>0</td>\n",
       "      <td>为什么我还款了不能再借？我每次还款都没预期啊提前还款为何不能再借了</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        sent1                  sent2  is_duplicate  \\\n",
       "3582                  何时可以受邀？                何时会激请我？             1   \n",
       "60498               如何更改还款卡号？             如何更换还款联系电话             0   \n",
       "53227     23号凌晨没存进去，白天存进去算逾期吗  。我今天早上还款算逾期吗？今天凌晨到期我晕             1   \n",
       "21333                  如何查看合同           可以帮我看一下合同真假吗             0   \n",
       "3885   为什么我还款了不能再借？我每次还款都没预期啊            提前还款为何不能再借了             0   \n",
       "\n",
       "                                    sent1+sent2  \n",
       "3582                             何时可以受邀？何时会激请我？  \n",
       "60498                       如何更改还款卡号？如何更换还款联系电话  \n",
       "53227  23号凌晨没存进去，白天存进去算逾期吗。我今天早上还款算逾期吗？今天凌晨到期我晕  \n",
       "21333                        如何查看合同可以帮我看一下合同真假吗  \n",
       "3885          为什么我还款了不能再借？我每次还款都没预期啊提前还款为何不能再借了  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81721a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of duplicate sents:  44924\n",
      "indexes of first ten duplicate sents: [3582, 53227, 51521, 10685, 41032, 49392, 65942, 2216, 81976, 85471]\n"
     ]
    }
   ],
   "source": [
    "data_duplicate = data_train[data_train['is_duplicate'] == 1] #filter the duplicated data\n",
    "td_index = list(data_duplicate.index)\n",
    "print('number of duplicate sents: ', len(td_index))\n",
    "print('indexes of first ten duplicate sents:', td_index[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1368427a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "何时可以受邀？\n",
      "何时会激请我？\n",
      "is_duplicate:  1\n"
     ]
    }
   ],
   "source": [
    "print(data_train['sent1'][3582])  #  Example of similar sentences\n",
    "print(data_train['sent2'][3582])\n",
    "print('is_duplicate: ', data_train['is_duplicate'][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50417a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "S1_train_words = np.array(data_train['sent1'][td_index])\n",
    "S2_train_words = np.array(data_train['sent2'][td_index])\n",
    "\n",
    "S1_test_words = np.array(data_test['sent1'])\n",
    "S2_test_words = np.array(data_test['sent2'])\n",
    "y_test  = np.array(data_test['is_duplicate'])\n",
    "data_train[\"sent1+sent2\"]=data_train[\"sent1+sent2\"][td_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb6f8067",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty arrays\n",
    "S1_train=np.asarray([None]*S1_train_words.shape[0])\n",
    "S2_train = np.asarray([None]*S2_train_words.shape[0])\n",
    "\n",
    "S1_test = np.asarray([None]*S1_test_words.shape[0])\n",
    "S2_test = np.asarray([None]*S2_test_words.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb2f14ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\Dell\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.728 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the vocabulary is:  4815\n"
     ]
    }
   ],
   "source": [
    "#Constructing the vocabulary with the train set      \n",
    "from collections import defaultdict\n",
    "\n",
    "vocab = defaultdict(lambda: 0)\n",
    "vocab['<PAD>'] = 1 #set pad as the first vocab\n",
    "\n",
    "for idx in td_index:                          #cut_all=False means the sentence was tokenized by semantic unit not character\n",
    "    word_list = \" \".join(jieba.cut(data_train.at[idx,\"sent1+sent2\"], cut_all=False)).split() #jieba tokenize will return an object\n",
    "    for w in word_list:\n",
    "        if w in vocab:\n",
    "            continue\n",
    "        else:\n",
    "            vocab[w] = len(vocab) + 1\n",
    "print('The length of the vocabulary is: ', len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c072cb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "483\n"
     ]
    }
   ],
   "source": [
    "print(vocab['<PAD>'])\n",
    "print(vocab['喝'])\n",
    "print(vocab['微'])  #if word not in vocabulary, returns 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b32f303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set was downsized to:  44924\n",
      "Test set length:  10000\n"
     ]
    }
   ],
   "source": [
    "print('Train set was downsized to: ', len(S1_train) ) \n",
    "print('Test set length: ', len(S1_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "051e378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting sents to array of integers\n",
    "for i in range(len(S1_train)):\n",
    "    S1_train[i] = [vocab[word] for word in S1_train_words[i]]\n",
    "    S2_train[i] = [vocab[word] for word in S2_train_words[i]]\n",
    "\n",
    "        \n",
    "for i in range(len(S1_test)):\n",
    "    S1_test[i] = [vocab[word] for word in S1_test_words[i]]\n",
    "    S2_test[i] = [vocab[word] for word in S2_test_words[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b1b4443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate sents:  44924\n",
      "The length of the training set is:   40431\n",
      "The length of the validation set is:  4493\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data to train and validation\n",
    "# shuffle the dataset\n",
    "np.random.shuffle(S1_train)\n",
    "np.random.shuffle(S2_train)\n",
    "split_n = int(len(S1_train)*.9)\n",
    "train_S1, train_S2 = S1_train[:split_n], S2_train[:split_n]\n",
    "val_S1, val_S2 = S1_train[split_n: ], S2_train[split_n:]\n",
    "print('Number of duplicate sents: ', len(S1_train))\n",
    "print(\"The length of the training set is:  \", len(train_S1))\n",
    "print(\"The length of the validation set is: \", len(val_S1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50e4194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(S1, S2, batch_size, pad=1, shuffle=True): #\"\"\"Generator function that yields batches of data\n",
    "    input1 = []\n",
    "    input2 = []\n",
    "    idx = 0\n",
    "    len_s = len(S1)\n",
    "    sents_indexes = [i for i in range(len_s)]\n",
    "    \n",
    "    if shuffle:\n",
    "        random.shuffle(sents_indexes)\n",
    "    \n",
    "    while True:\n",
    "        if idx >= len_s:\n",
    "            # if idx is greater than or equal to len_q, set idx to 0 \n",
    "            idx = 0\n",
    "            # shuffle to get random batches if shuffle is set to True\n",
    "            if shuffle:\n",
    "                random.shuffle(sents_indexes)\n",
    "        \n",
    "        # get sents at the sents[idx] position in sent1 and sent2\n",
    "        s1 = S1[sents_indexes[idx]]\n",
    "        s2 = S2[sents_indexes[idx]]\n",
    "        \n",
    "        # increment idx by 1\n",
    "        idx += 1\n",
    "        # append q1\n",
    "        input1.append(s1)\n",
    "        # append q2\n",
    "        input2.append(s2)\n",
    "        if len(input1) == batch_size:\n",
    "            # take max of input1 & input2 and then max out of the two of them.\n",
    "            max_len = max(max([len(q) for q in input1]),\n",
    "                          max([len(q) for q in input2]))\n",
    "            max_len = 2**int(np.ceil(np.log2(max_len)))# for the computation\n",
    "            for idx,(s1, s2) in enumerate(zip(input1, input2)):\n",
    "                # add [pad] to q1 until it reaches max_len\n",
    "                input1[idx] = s1 + [pad] * (max_len - len(s1))\n",
    "                input2[idx] = s2 + [pad] * (max_len - len(s2))\n",
    "            yield np.array(input1), np.array(input2) # will stop the while loop\n",
    "            # reset the batches\n",
    "            input1, input2 = [], []  # reset the batches the next operation will start from the first line after yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24270270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First sents  :  \n",
      " [[ 910 2397  755 1039 1938  171    1    1    1    1    1    1    1    1\n",
      "     1    1]\n",
      " [1071 4259  281   33 2231 1015 1001    1    1    1    1    1    1    1\n",
      "     1    1]\n",
      " [ 473 2143 1358   19    1    1    1    1    1    1    1    1    1    1\n",
      "     1    1]] \n",
      "\n",
      "Second sents :  \n",
      " [[1071 4259 2052  910    0  861  208    1    1    1    1    1    1    1\n",
      "     1    1]\n",
      " [1131 4802  755 1039 1201   10   78  959   14  473 3366 1938   74    1\n",
      "     1    1]\n",
      " [  53  405    0    0  104  105    0    0  133    1    1    1    1    1\n",
      "     1    1]]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "batch1, batch2 = next(data_generator(train_S1, train_S2, batch_size))\n",
    "print(\"First sents  : \",'\\n', batch1, '\\n')\n",
    "print(\"Second sents : \",'\\n', batch2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd0eb38",
   "metadata": {},
   "source": [
    "# Define the model and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "74cdf590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Siamese(vocab_size=len(vocab), d_model=128, mode='train'):\n",
    "\n",
    "    def normalize(x):  # normalizes the vectors to have L2 norm which is better than L1 norm\n",
    "        return x / fastnp.power(fastnp.sum(x**2, axis=-1, keepdims=True),0.5)\n",
    "    \n",
    "    \n",
    "    s_processor = tl.Serial(                      \n",
    "        tl.Embedding(vocab_size, d_model),\n",
    "        # Run GRU. If this is not dim d_model it raises an error\n",
    "        tl.GRU(d_model),\n",
    "        tl.Mean(axis=1),  #calculate the mean for normalization\n",
    "        tl.Fn('Normalize', lambda x: normalize(x)))\n",
    "        # Apply normalize function  # Returns one vector of shape [batch_size, d_model].\n",
    "    \n",
    "\n",
    "    \n",
    "    # Run on S1 and S2 in parallel.\n",
    "    model = tl.Parallel(s_processor, s_processor)# Processor will run on both S1 and S2.\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "970bcb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallel_in2_out2[\n",
      "  Serial[\n",
      "    Embedding_5605_128\n",
      "    GRU_128\n",
      "    Mean\n",
      "    Normalize\n",
      "  ]\n",
      "  Serial[\n",
      "    Embedding_5605_128\n",
      "    GRU_128\n",
      "    Mean\n",
      "    Normalize\n",
      "  ]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# check the model architecture\n",
    "model = Siamese()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b835bdfc",
   "metadata": {},
   "source": [
    "## Mean negative examples will accelerate the training and closest negative examples contribute to penalizing the cost more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "72ffc141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TripletLossFn(v1, v2, margin=0.25):\n",
    "    \n",
    "    # use fastnp to take the dot product of the two batches and the second one needs to be transposed\n",
    "    scores = fastnp.dot(v1, v2.T)  # pairwise cosine similarity\n",
    "    # calculate new batch size\n",
    "    batch_size = len(scores)\n",
    "    # use fastnp to get all postive `diagonal` entries in `scores`\n",
    "    positive = fastnp.diagonal(scores)  # the positive ones (duplicates)\n",
    "    empty=np.zeros([batch_size,batch_size])\n",
    "    np.fill_diagonal(empty,1)\n",
    "    # multiply `empty` with 2.0 and subtract it out of `scores`\n",
    "    negative_without_positive = scores - 2.0 * empty\n",
    "    # take the row by row `max` of `negative_without_positive`. \n",
    "    closest_negative = negative_without_positive.max(axis=1) #  means cloest negative examples\n",
    "    # subtract `fastnp.eye(batch_size)` out of 1.0 and do element-wise multiplication with `scores`\n",
    "    negative_zero_on_duplicate = scores * (1.0 - empty)\n",
    "    # use `fastnp.sum` on `negative_zero_on_duplicate` for `axis=1` and divide it by `(batch_size - 1)` \n",
    "    mean_negative = np.sum(negative_zero_on_duplicate, axis=1) / (batch_size-1) # get the mean value of negative examples\n",
    "    # compute `fastnp.maximum` among 0.0 and `A`\n",
    "    triplet_loss1 = fastnp.maximum(0.0, margin - positive + closest_negative)\n",
    "    # compute `fastnp.maximum` among 0.0 and `B`\n",
    "    triplet_loss2 = fastnp.maximum(0.0, margin - positive + mean_negative)\n",
    "    # add the two losses together and take the `fastnp.mean` of it\n",
    "    triplet_loss = fastnp.mean(triplet_loss1 + triplet_loss2) # make sure the model will learn more neagtive examples\n",
    "    \n",
    "    \n",
    "    return triplet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f315e977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial # fix the margin, so we don't have call margin everytime\n",
    "def TripletLoss(margin=0.25):\n",
    "    triplet_loss_fn = partial(TripletLossFn, margin=margin)\n",
    "    return tl.Fn('TripletLoss', triplet_loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c27a531a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_S1.shape  (40431,)\n",
      "val_S1.shape    (4493,)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "train_generator = data_generator(train_S1, train_S2, batch_size, vocab['<PAD>'])\n",
    "val_generator = data_generator(val_S1, val_S2, batch_size, vocab['<PAD>'])\n",
    "print('train_S1.shape ', train_S1.shape)\n",
    "print('val_S1.shape   ', val_S1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a389706f",
   "metadata": {},
   "source": [
    "# Train the model and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d7da28e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = trax.lr.warmup_and_rsqrt_decay(400, 0.01) # apply the warmup strategy #Value for learning rate after warm-up has finished\n",
    "\n",
    "def train_model(lr_schedule, train_generator=train_generator, val_generator=val_generator, output_dir='model/'):\n",
    "    \n",
    "    output_dir = os.path.dirname(output_dir)\n",
    "\n",
    "\n",
    "    train_task = training.TrainTask(\n",
    "        labeled_data=train_generator,         # Use generator (train)\n",
    "        loss_layer=TripletLoss(),             # Use triplet loss. \n",
    "        optimizer=trax.optimizers.Adafactor(0.01), # chosse the Adafactor as the optimizer\n",
    "        lr_schedule=lr_schedule,              # Use Trax multifactor schedule function\n",
    "    )\n",
    "\n",
    "    eval_task = training.EvalTask(\n",
    "        labeled_data=val_generator,       # Use generator (val)\n",
    "        metrics=[TripletLoss()],          # Use triplet loss. \n",
    "    )\n",
    "    \n",
    "\n",
    "    training_loop = training.Loop(Siamese(),\n",
    "                                  train_task,\n",
    "                                  eval_tasks=[eval_task],\n",
    "                                  output_dir=output_dir,\n",
    "                                 random_seed=34) #set the random seed to keep the same result each time\n",
    "\n",
    "    return training_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4270b47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_S1, test_S2, y, threshold, model, vocab, data_generator=data_generator, batch_size=64):\n",
    "    accuracy = 0\n",
    "    for i in range(0, len(test_S1), batch_size):\n",
    "        # Call the data generator with shuffle=False using next()\n",
    "        # use batch size chuncks of sentences as S1 & S2 arguments of the data generator. \n",
    "        s1, s2 = next(data_generator(test_S1[i:i + batch_size], test_S2[i:i + batch_size], batch_size, vocab['<PAD>'], shuffle=False))\n",
    "        # use batch size chuncks of actual output targets\n",
    "        y_test2 = y[i:i + batch_size]\n",
    "        # Call the model\n",
    "        v1, v2 = model((s1, s2)) \n",
    "\n",
    "        for j in range(batch_size):\n",
    "            # take dot product to compute cos similarity of each pair of entries, v1[j], v2[j]\n",
    "            d = np.dot(v1[j], v2[j].T) # second one needs to be transposed\n",
    "            # is d greater than the threshold?\n",
    "            res = d > threshold\n",
    "            # increment accurancy if y_test is equal `res`\n",
    "            accuracy += (y_test2[j] == res)\n",
    "    # compute accuracy using accuracy and total length of test sentences\n",
    "    accuracy = accuracy / len(test_S1)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c4ffcb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sent1, sent2,  model, vocab, data_generator=data_generator, verbose=False):\n",
    "\n",
    "    # use jieba word tokenize function to tokenize Chinese characters\n",
    "    s1 = \" \".join(jieba.cut(sent1, cut_all=False)).split()  # tokenize\n",
    "    s2 = \" \".join(jieba.cut(sent2, cut_all=False)).split()  # tokenize\n",
    "    S1, S2 = [], []\n",
    "    for word in s1:  # encode s1\n",
    "        # increment by checking the 'word' index in `vocab`\n",
    "        S1 += [vocab[word]]\n",
    "    for word in s2:  # encode s2\n",
    "        # increment by checking the 'word' index in `vocab`\n",
    "        S2 += [vocab[word]]\n",
    "        \n",
    "    # Call the data generator  using next()\n",
    "    # pass [s1] & [s2] as s1 & s2 arguments of the data generator. Set batch size as 1\n",
    "    S1, S2 = next(data_generator([S1], [S2], 1, vocab['<PAD>']))\n",
    "    # Call the model\n",
    "    v1, v2 = model((S1, S2)) \n",
    "    # take dot product to compute cos similarity of each pair of entries, v1, v2\n",
    "    d = np.dot(v1[0], v2[0].T) #get the similarity score\n",
    "    \n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "38b30697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step      1: Total number of trainable weights: 816256\n",
      "Step      1: Ran 1 train steps in 5.79 secs\n",
      "Step      1: train TripletLoss |  0.50076336\n",
      "Step      1: eval  TripletLoss |  0.50642514\n",
      "\n",
      "Step    100: Ran 99 train steps in 114.24 secs\n",
      "Step    100: train TripletLoss |  0.50036424\n",
      "Step    100: eval  TripletLoss |  0.50189894\n",
      "\n",
      "Step    200: Ran 100 train steps in 147.81 secs\n",
      "Step    200: train TripletLoss |  0.48591897\n",
      "Step    200: eval  TripletLoss |  1.04569507\n",
      "\n",
      "Step    300: Ran 100 train steps in 152.23 secs\n",
      "Step    300: train TripletLoss |  0.21912900\n",
      "Step    300: eval  TripletLoss |  1.11851835\n",
      "\n",
      "Step    400: Ran 100 train steps in 147.46 secs\n",
      "Step    400: train TripletLoss |  0.14935488\n",
      "Step    400: eval  TripletLoss |  1.07237673\n",
      "\n",
      "Step    500: Ran 100 train steps in 149.09 secs\n",
      "Step    500: train TripletLoss |  0.10622285\n",
      "Step    500: eval  TripletLoss |  1.14495122\n",
      "\n",
      "Step    600: Ran 100 train steps in 153.19 secs\n",
      "Step    600: train TripletLoss |  0.06816491\n",
      "Step    600: eval  TripletLoss |  1.12711859\n",
      "\n",
      "Step    700: Ran 100 train steps in 165.63 secs\n",
      "Step    700: train TripletLoss |  0.03428349\n",
      "Step    700: eval  TripletLoss |  1.12537706\n",
      "\n",
      "Step    800: Ran 100 train steps in 153.73 secs\n",
      "Step    800: train TripletLoss |  0.03313859\n",
      "Step    800: eval  TripletLoss |  1.12764692\n"
     ]
    }
   ],
   "source": [
    "train_steps = 800\n",
    "training_loop = train_model(lr_schedule)\n",
    "training_loop.run(train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c1860a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(((array([[-0.10104602,  0.02889115, -0.10710341, ...,  0.17211324,\n",
       "            0.11238155, -0.00545579],\n",
       "          [-0.00494196,  0.00592238, -0.08847794, ..., -0.02457219,\n",
       "            0.12076508, -0.00646752],\n",
       "          [ 0.07731185,  0.11890233, -0.08921237, ...,  0.14748329,\n",
       "            0.13896737, -0.12982987],\n",
       "          ...,\n",
       "          [ 0.11542351, -0.08621721,  0.13382736, ..., -0.09279124,\n",
       "           -0.03013758, -0.136706  ],\n",
       "          [-0.10708649,  0.11113342,  0.10610324, ..., -0.079561  ,\n",
       "           -0.12771045,  0.02540564],\n",
       "          [-0.09707364,  0.12381083, -0.07750284, ...,  0.01700191,\n",
       "           -0.09695008,  0.13629757]], dtype=float32),\n",
       "   (((), ((), ())),\n",
       "    ((array([[ 0.00669629,  0.00151234, -0.01979298, ...,  0.00151354,\n",
       "              -0.01387604, -0.00649653],\n",
       "             [-0.00878541,  0.02212545,  0.00285433, ..., -0.00119053,\n",
       "              -0.00374965, -0.00775282],\n",
       "             [-0.0116117 , -0.02906881, -0.02117639, ...,  0.01683593,\n",
       "               0.01514259, -0.00663863],\n",
       "             ...,\n",
       "             [ 0.00629329, -0.00417276, -0.01539519, ..., -0.0466993 ,\n",
       "               0.00096661, -0.00386243],\n",
       "             [ 0.00794105,  0.00833974,  0.0039696 , ...,  0.0141088 ,\n",
       "               0.00142212, -0.01259779],\n",
       "             [-0.0119037 ,  0.00328826,  0.00295092, ..., -0.00911815,\n",
       "              -0.00416698, -0.0067321 ]], dtype=float32),\n",
       "      array([ 2.7172975e-03,  3.4131336e-03,  3.5911335e-03,  2.3488302e-03,\n",
       "              2.8683671e-03,  2.9933034e-03,  3.1571996e-03,  2.5765786e-03,\n",
       "              3.2063676e-03,  2.0536373e-03,  2.1853938e-03,  2.4095098e-03,\n",
       "              2.4843067e-03,  3.3314731e-03,  2.5992044e-03,  2.2824239e-03,\n",
       "              2.8791968e-03,  3.2611957e-03,  1.9096690e-03,  2.3752477e-03,\n",
       "              3.9072083e-03,  2.4534280e-03,  3.0449624e-03,  2.5984496e-03,\n",
       "              3.3107663e-03,  2.4499311e-03,  2.5402689e-03,  2.0379410e-03,\n",
       "              3.3787023e-03,  3.2937541e-03,  2.6778330e-03,  2.8689997e-03,\n",
       "              2.8096684e-03,  2.8174792e-03,  3.2589247e-03,  2.2517231e-03,\n",
       "              2.4677555e-03,  1.9854316e-03,  2.9693258e-03,  2.6633409e-03,\n",
       "              2.6014452e-03,  3.3074345e-03,  2.2595655e-03,  3.2647105e-03,\n",
       "              2.8157351e-03,  2.6961488e-03,  3.7232025e-03,  3.4923395e-03,\n",
       "              3.4121326e-03,  3.1898646e-03,  2.8985871e-03,  3.0160088e-03,\n",
       "              2.5626945e-03,  3.2155192e-03,  3.3481428e-03,  3.2335173e-03,\n",
       "              3.5972113e-03,  3.7477037e-03,  3.0527182e-03,  3.1468526e-03,\n",
       "              2.5126326e-03,  1.4613502e-03,  2.4105865e-03,  2.8274541e-03,\n",
       "              2.7738260e-03,  2.8600083e-03,  2.9451018e-03,  2.2259990e-03,\n",
       "              3.0135387e-03,  3.2987036e-03,  3.9460687e-03,  3.1324513e-03,\n",
       "              3.1270471e-03,  3.4069812e-03,  2.9327993e-03,  2.1315939e-03,\n",
       "              2.6626098e-03,  3.6225482e-03,  2.7920129e-03,  2.6856491e-03,\n",
       "              2.8588988e-03,  2.9820364e-03,  3.2574886e-03,  3.4151059e-03,\n",
       "              3.4524314e-03,  2.3729361e-03,  2.4138445e-03,  2.7767492e-03,\n",
       "              2.4548897e-03,  2.4481886e-03,  3.6189246e-03,  3.5349990e-03,\n",
       "              2.7033326e-03,  3.1326555e-03,  2.7309724e-03,  3.0214328e-03,\n",
       "              2.4713124e-03,  2.3515339e-03,  2.7958436e-03,  2.5964659e-03,\n",
       "              3.5557800e-03,  2.5973073e-03,  2.5044314e-03,  2.3087498e-03,\n",
       "              2.6586438e-03,  2.4523081e-03,  2.4676046e-03,  3.0822593e-03,\n",
       "              2.7661223e-03,  2.9645870e-03,  2.2870698e-03,  3.4934664e-03,\n",
       "              2.7909472e-03,  3.2078072e-03,  2.7020269e-03,  3.1641817e-03,\n",
       "              2.8322702e-03,  2.9450909e-03,  3.6648391e-03,  2.5958803e-03,\n",
       "              1.6062141e-03,  3.1553993e-03,  3.1961738e-03,  2.8003526e-03,\n",
       "              3.0796300e-03,  2.1179032e-03,  2.8912853e-03,  3.2159649e-03,\n",
       "              9.2182070e-04,  7.4613304e-04,  1.0764009e-03,  1.1785644e-03,\n",
       "              1.3477801e-03,  9.3217497e-04,  2.7479627e-04,  1.0899636e-03,\n",
       "              8.9698139e-04,  4.3708639e-04,  1.8258510e-03,  1.1999370e-03,\n",
       "              5.6958792e-04,  1.1994870e-03,  1.5326146e-03,  8.1703387e-04,\n",
       "             -3.3831134e-04,  1.3029684e-03,  3.4241957e-04,  1.9130045e-04,\n",
       "              1.2019320e-03,  1.2233853e-03,  1.2685186e-03,  1.3653828e-03,\n",
       "              5.9194700e-04,  9.6313201e-04,  3.9709528e-04,  4.8358575e-04,\n",
       "              9.0886670e-04,  2.5642421e-03,  1.5621609e-03,  1.1578857e-03,\n",
       "              1.2770991e-04,  2.3809209e-04,  1.4069789e-03,  5.8377301e-04,\n",
       "              1.0293412e-03,  8.8425213e-04,  1.5772607e-04,  1.3419251e-03,\n",
       "              3.0858035e-04,  3.0236313e-04,  1.4788163e-03,  1.9335079e-03,\n",
       "              1.3099045e-03,  1.1746504e-03,  1.4652208e-03,  6.5624842e-04,\n",
       "              1.1856899e-03,  5.2538147e-04,  1.3526796e-03,  1.6948030e-03,\n",
       "              9.9205354e-04,  3.6654979e-04,  2.5332686e-03,  1.6005582e-04,\n",
       "              8.5076387e-04,  2.6397433e-04,  1.2091424e-03,  1.7855377e-03,\n",
       "              1.4588049e-03,  2.6381103e-04,  8.2136813e-04,  2.0593577e-03,\n",
       "              1.7991511e-04,  3.1782364e-04,  1.9963635e-03,  1.6743217e-04,\n",
       "              7.6517893e-04,  9.8036113e-04,  8.5298397e-04,  1.3242846e-03,\n",
       "              1.5691549e-03,  1.3662159e-03,  5.3645711e-04,  3.4392864e-04,\n",
       "              6.3983066e-04,  1.1338175e-03,  3.3961490e-04,  6.5512193e-04,\n",
       "              3.4949125e-04,  7.8246859e-04,  2.6442065e-05,  1.0516566e-03,\n",
       "              1.0078086e-03,  9.0922334e-04, -1.9992501e-04,  9.0456428e-04,\n",
       "              5.1873381e-04,  7.1382918e-04,  1.6689929e-04,  1.4565684e-03,\n",
       "             -5.5659248e-06,  1.3677079e-03,  1.5292303e-03,  1.6461455e-03,\n",
       "              5.4290035e-04,  5.8033137e-04, -9.4041723e-05,  4.2370331e-04,\n",
       "              2.0547383e-03, -2.4066670e-05,  5.9894996e-04,  3.5930399e-04,\n",
       "              1.1327368e-03,  1.5992287e-03,  1.9341272e-04,  1.3429653e-03,\n",
       "              1.6820073e-03,  3.9478467e-04,  1.4541458e-04,  7.0795586e-04,\n",
       "              2.5332544e-04,  1.4177602e-03,  5.2481581e-04,  7.0130581e-04,\n",
       "              1.2917421e-03,  4.8686765e-04,  6.8736332e-04,  5.4779672e-04,\n",
       "              1.0253254e-03,  1.5065414e-03,  1.6334871e-03, -1.9602840e-04,\n",
       "              5.8360095e-04,  1.7469613e-03, -5.7346613e-05,  9.2077738e-04],\n",
       "            dtype=float32),\n",
       "      array([[-4.7630398e-03, -4.4056745e-03,  8.3487714e-03, ...,\n",
       "               8.9648733e-04, -1.3445303e-03,  2.1238632e-03],\n",
       "             [ 6.1090644e-03,  8.2720015e-03,  9.6775014e-03, ...,\n",
       "               4.0399609e-03, -4.6348795e-03,  1.7301189e-03],\n",
       "             [ 1.3852910e-03, -3.3930806e-03,  8.7698149e-03, ...,\n",
       "              -1.5399182e-03, -6.0071889e-03, -3.9351718e-03],\n",
       "             ...,\n",
       "             [ 5.5440068e-03,  7.0382492e-05,  1.0973110e-02, ...,\n",
       "               1.1678139e-02, -3.0311666e-04, -7.6148016e-03],\n",
       "             [-1.4575353e-03, -2.3873679e-03,  1.8537036e-03, ...,\n",
       "               7.5888773e-03,  5.2493992e-03, -5.6006918e-03],\n",
       "             [ 9.1669643e-03,  5.2996812e-04,  5.1063802e-03, ...,\n",
       "               7.9051862e-03,  6.9210711e-03, -6.8742023e-03]], dtype=float32),\n",
       "      array([-1.60297641e-04, -3.25034489e-04, -2.21203882e-04, -1.87723810e-04,\n",
       "              1.75815774e-04,  3.61683597e-05, -2.54953804e-04, -3.77672375e-04,\n",
       "              1.18376120e-04,  2.14520391e-04,  2.20333328e-04, -2.14415617e-04,\n",
       "              1.60624390e-04, -3.81378311e-04,  9.52859918e-05, -8.98960861e-05,\n",
       "              1.47758430e-04,  2.69508804e-04, -1.91863131e-04, -1.63806588e-04,\n",
       "              2.35727712e-04,  1.29545471e-04, -8.51924488e-05, -4.81541210e-05,\n",
       "             -2.38582536e-04,  1.24506972e-04, -3.91690584e-04,  6.51762311e-05,\n",
       "              1.61590753e-04,  3.10342148e-04,  1.30455128e-05,  2.01842573e-04,\n",
       "             -6.21395884e-05, -3.77507786e-05,  1.42310892e-04,  8.54605823e-05,\n",
       "              3.90243513e-04, -1.05271785e-04, -1.09221248e-04, -6.47360575e-05,\n",
       "              1.51396534e-05, -4.00036719e-04, -1.89797895e-04, -1.39812546e-04,\n",
       "              2.79930158e-04, -2.65890209e-04,  4.96819906e-04,  3.38363861e-05,\n",
       "             -7.19260715e-05,  8.37025655e-05, -2.16911474e-04,  9.39963211e-05,\n",
       "             -2.21526221e-04, -2.24850119e-05,  3.56956123e-04,  6.91645182e-05,\n",
       "              4.45157493e-05, -2.75575992e-04, -5.19360256e-05,  2.92477023e-04,\n",
       "              1.48186737e-04, -1.68063125e-04,  2.55748455e-04,  2.08778856e-05,\n",
       "              1.76475252e-04, -4.79147566e-05, -4.30856562e-05, -2.61791254e-04,\n",
       "             -3.93015973e-04, -4.44826379e-04,  3.04897258e-04,  2.00994284e-04,\n",
       "             -7.01659374e-05, -3.16976220e-04, -2.22946430e-04, -3.80146696e-04,\n",
       "             -4.24351892e-05,  2.56902276e-04,  2.58502376e-04, -1.80770119e-04,\n",
       "              4.33726091e-05,  8.64280082e-05, -2.30448000e-04, -3.30924842e-04,\n",
       "             -2.20409071e-04,  3.41844570e-04,  5.50197612e-04,  4.03070771e-05,\n",
       "              1.05322113e-04,  9.58576784e-05,  1.15596144e-04, -2.30718448e-04,\n",
       "              1.12953257e-05,  5.12145518e-04, -1.04203376e-04, -3.94136703e-04,\n",
       "             -2.06623299e-04, -1.30694621e-04, -3.93181072e-05,  1.34267626e-04,\n",
       "             -3.37420526e-04, -1.13842892e-04,  9.93770736e-05,  1.27744061e-05,\n",
       "              2.07747187e-04, -1.63753837e-04,  4.30455024e-04, -1.19821467e-04,\n",
       "              1.14530005e-04, -9.88602260e-05, -2.30259684e-04, -8.57964915e-05,\n",
       "             -1.72932589e-04, -2.03079544e-04, -2.04701646e-04, -2.09383448e-04,\n",
       "              2.32563267e-04, -3.69023473e-05,  1.74424713e-04, -1.50219334e-04,\n",
       "              2.28459088e-04,  2.37525906e-04,  1.54654917e-04, -1.99762842e-04,\n",
       "              1.27494626e-04, -3.33568052e-04,  1.07285268e-04, -1.49797503e-04],\n",
       "            dtype=float32)),),\n",
       "    ()),\n",
       "   (),\n",
       "   ()),\n",
       "  {'__marker_for_cached_weights_': ()}),\n",
       " (((), (((), ((), ())), ((), ()), ()), (), ()),\n",
       "  {'__marker_for_cached_state_': ()}))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Siamese()\n",
    "model.init_from_file('./model/model.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "5cfaeb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.5254\n"
     ]
    }
   ],
   "source": [
    "accuracy = test(S1_test,S2_test, y_test, 0.7, model, vocab, batch_size = 500) \n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40aecc1",
   "metadata": {},
   "source": [
    "## Assume \"他很好\" is reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "d00eeedf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96708274"
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"他很好\",\"他非常好\",model,vocab,verbose=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d513041",
   "metadata": {},
   "source": [
    "based on the result below, we can see that if we use bleu score to evlauate it, the 1 gram score will be 0.5, but actually these two sentences have pretty much same meaning. If we use rogue elvaluation metric, the score will be 0.67, which can not still reflect the real MT quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "c951cfc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8861375"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"他很好\",\"他很出色\",model,vocab,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03095305",
   "metadata": {},
   "source": [
    "## Assume \"怎样修改号码 is reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "282b5fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7488622"
      ]
     },
     "execution_count": 668,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"怎样修改号码\",\"如何修改号码\",model,vocab,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "49bb3236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7620132"
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"怎样修改号码\",\"怎样改变号码\",model,vocab,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644abaa4",
   "metadata": {},
   "source": [
    "## Train the model with less steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "2fa2d87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step      1: Total number of trainable weights: 816128\n",
      "Step      1: Ran 1 train steps in 5.03 secs\n",
      "Step      1: train TripletLoss |  0.50999707\n",
      "Step      1: eval  TripletLoss |  0.50219840\n",
      "\n",
      "Step    100: Ran 99 train steps in 73.89 secs\n",
      "Step    100: train TripletLoss |  0.50474632\n",
      "Step    100: eval  TripletLoss |  0.50047755\n",
      "\n",
      "Step    200: Ran 100 train steps in 77.71 secs\n",
      "Step    200: train TripletLoss |  0.47630322\n",
      "Step    200: eval  TripletLoss |  0.57024050\n",
      "\n",
      "Step    300: Ran 100 train steps in 78.18 secs\n",
      "Step    300: train TripletLoss |  0.13668355\n",
      "Step    300: eval  TripletLoss |  0.75268292\n"
     ]
    }
   ],
   "source": [
    "train_steps = 300\n",
    "training_loop = train_model(lr_schedule,output_dir='model2/')\n",
    "training_loop.run(train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "aac034bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((array([[-0.09794217,  0.07738896, -0.11017518, ...,  0.10171206,\n",
       "            0.04932896, -0.01923384],\n",
       "          [-0.0230925 ,  0.00876028, -0.11206853, ..., -0.04132047,\n",
       "            0.11689867, -0.00949296],\n",
       "          [ 0.07769928,  0.11949887, -0.08965942, ...,  0.14822248,\n",
       "            0.1396659 , -0.13048118],\n",
       "          ...,\n",
       "          [ 0.11600288, -0.08664934,  0.13449791, ..., -0.0932569 ,\n",
       "           -0.03028884, -0.13739145],\n",
       "          [-0.10762369,  0.11169153,  0.10663596, ..., -0.07995961,\n",
       "           -0.1283512 ,  0.02553323],\n",
       "          [-0.09756147,  0.12443251, -0.0778916 , ...,  0.01708739,\n",
       "           -0.09743696,  0.13698302]], dtype=float32),\n",
       "   (((), ((), ())),\n",
       "    ((array([[ 9.78134479e-03,  8.52713478e-04, -5.36919106e-03, ...,\n",
       "               1.00522665e-02, -4.56843816e-04, -9.80535173e-04],\n",
       "             [-6.45524589e-03,  9.66709387e-03, -5.77989733e-03, ...,\n",
       "               5.65170031e-03,  5.55751147e-04, -3.93061247e-03],\n",
       "             [ 9.50212780e-05, -3.70890251e-03, -4.31095157e-03, ...,\n",
       "               7.80677376e-03,  7.84886070e-03,  3.71012633e-04],\n",
       "             ...,\n",
       "             [ 5.21848584e-03, -9.65342391e-03, -7.86657911e-03, ...,\n",
       "              -4.04192630e-04,  5.62546123e-03,  1.11694867e-02],\n",
       "             [ 9.87836905e-03,  1.58862933e-03, -1.25138706e-03, ...,\n",
       "              -4.72758012e-03, -1.16065452e-02, -4.27239155e-03],\n",
       "             [-3.95928416e-03, -8.82230175e-04, -5.74286003e-03, ...,\n",
       "              -5.09995408e-03,  4.71123820e-03, -1.98128596e-02]], dtype=float32),\n",
       "      array([ 7.80639763e-04,  7.15560163e-04,  5.30883379e-04,  3.00798303e-04,\n",
       "              1.93034852e-04,  5.63413603e-04,  2.65491311e-04,  2.80066044e-04,\n",
       "              7.73893262e-04,  2.03696589e-04,  2.85073795e-04,  9.13565862e-04,\n",
       "              3.10793519e-04,  9.21230530e-04,  9.12593794e-04,  5.17111621e-04,\n",
       "              6.94077811e-04,  3.81765974e-04,  2.56928644e-04,  2.81083572e-04,\n",
       "              4.69718070e-04,  3.05000227e-04,  6.04019791e-04,  7.10269320e-04,\n",
       "              3.66172317e-04,  4.32423491e-04,  2.62028247e-04,  2.76058621e-04,\n",
       "              8.94049008e-04,  8.12784652e-04,  7.84939155e-04,  3.39843536e-04,\n",
       "              5.65601338e-04,  1.01355882e-03,  5.00326336e-04,  8.62811692e-04,\n",
       "              1.88294915e-04,  5.93710865e-04,  3.76058277e-04,  5.68830641e-04,\n",
       "              6.15867903e-04,  5.09608595e-04,  5.68392279e-04,  3.52159550e-04,\n",
       "              8.44607654e-04,  6.38066151e-04,  7.08170119e-04,  5.65092720e-04,\n",
       "              6.59234531e-04,  4.55541158e-04,  5.51193138e-04,  5.27683180e-04,\n",
       "              4.58585855e-04,  8.04905023e-04,  5.97720908e-04,  6.81599195e-04,\n",
       "              5.73714206e-04,  5.91798918e-04,  5.19574562e-04,  6.35304546e-04,\n",
       "              6.84667146e-04,  2.09762293e-04,  3.84247513e-04,  7.20548094e-04,\n",
       "              9.92620946e-04,  9.87088424e-04,  2.80172040e-04,  2.25621232e-04,\n",
       "              8.36109859e-04,  9.11366835e-04,  5.23910043e-04,  2.69251410e-04,\n",
       "              5.78023319e-04,  7.45679659e-04,  7.02208374e-04,  3.22470267e-04,\n",
       "              7.27042672e-04,  6.27940171e-04,  8.54076236e-04,  3.49233043e-04,\n",
       "              6.79989287e-04,  5.10516344e-04,  8.99837120e-04,  6.44674641e-04,\n",
       "              6.17121172e-04,  7.18632655e-04,  6.80530618e-04,  6.49062218e-04,\n",
       "              4.51095315e-04,  2.25696029e-04,  6.91475754e-04,  5.01735776e-04,\n",
       "              8.00372043e-04,  3.67522938e-04,  3.18591308e-04,  6.88114786e-04,\n",
       "              2.32501261e-04,  7.64495984e-04,  1.01299048e-03,  4.13838832e-04,\n",
       "              5.13605424e-04,  6.34260796e-05,  5.23913943e-04,  2.73300626e-04,\n",
       "              2.18232803e-04,  2.50782090e-04,  7.33003544e-04,  4.70242609e-04,\n",
       "              4.45958809e-04,  6.26104709e-04,  1.40095115e-04,  4.44092293e-04,\n",
       "              6.73041563e-04,  3.29747272e-04,  6.34476542e-04,  5.98502171e-04,\n",
       "              3.72711715e-04,  9.23510524e-04,  6.58697798e-04,  6.36536512e-04,\n",
       "              2.28392426e-04,  5.88189345e-04,  3.36009572e-04,  6.63056737e-04,\n",
       "              4.55942383e-04,  2.45919131e-04,  5.94147772e-04,  3.18724895e-04,\n",
       "              2.24551986e-04,  9.24662527e-05,  1.71620632e-04,  2.49651494e-04,\n",
       "              3.44949920e-04, -1.72996966e-04, -9.30189635e-05,  1.75000532e-04,\n",
       "             -1.46523700e-04,  2.94807804e-04,  4.49239102e-04,  3.58965306e-04,\n",
       "              2.61595560e-04,  8.72291712e-05,  7.35631795e-04,  7.37951603e-04,\n",
       "             -1.00242418e-04,  4.92131454e-04, -1.70506042e-04, -8.60194268e-05,\n",
       "             -1.59491930e-04,  3.15990968e-04,  5.73789992e-04, -4.87875572e-04,\n",
       "              2.98401021e-04,  3.49217444e-04, -2.83389207e-04,  6.70039677e-04,\n",
       "              1.44794121e-05, -1.75050227e-04,  1.96317109e-04,  2.21720256e-04,\n",
       "              2.55556690e-04,  2.23540046e-04,  7.00976816e-04,  7.87544122e-04,\n",
       "              2.68873177e-04,  4.85835008e-05, -1.22164667e-04,  4.55885165e-05,\n",
       "             -7.44602903e-06,  5.56091254e-05,  6.60362130e-04,  2.90079886e-04,\n",
       "              3.38379003e-04,  1.99529051e-04,  3.14013421e-04,  3.37517937e-04,\n",
       "              1.38187897e-04,  3.50879156e-04,  2.90237309e-04,  7.66376688e-05,\n",
       "              2.42467882e-04,  1.98813577e-04,  6.91405730e-04, -1.07252934e-04,\n",
       "              3.18811333e-04,  7.76119414e-05,  4.60659212e-04,  1.84506804e-04,\n",
       "              2.71068537e-04,  3.05418274e-04,  2.84004636e-04,  5.89253323e-05,\n",
       "             -9.84548569e-06,  4.28385538e-04, -1.68354294e-04,  1.09890345e-04,\n",
       "              3.30446957e-04,  3.96003743e-04,  2.48007040e-04,  3.66479304e-04,\n",
       "              1.58502502e-04,  1.22768921e-04,  1.08442277e-04, -2.51158373e-04,\n",
       "              5.57266932e-04, -1.24612809e-04,  2.51706260e-05,  2.59251450e-04,\n",
       "              3.84168634e-05,  1.24890284e-04,  2.59444842e-05,  2.09660022e-04,\n",
       "              2.47594027e-04,  6.50410133e-04,  3.60531703e-04,  3.97716620e-04,\n",
       "              4.36914735e-04,  3.06296803e-04,  1.89057740e-04,  4.59519681e-04,\n",
       "             -7.80544360e-05,  1.58783674e-04,  2.90062424e-04,  1.62454176e-04,\n",
       "              3.53335374e-04,  3.69301473e-04,  1.30947941e-04,  1.45753613e-04,\n",
       "             -4.52589447e-04,  2.61983310e-04,  4.71133157e-04,  4.84906050e-04,\n",
       "              4.15768562e-04,  8.81036467e-05,  6.91455498e-05,  2.43568938e-04,\n",
       "              2.36929482e-04,  1.96284149e-04,  1.22777768e-04,  9.56183139e-05,\n",
       "              2.45023286e-04,  2.89631134e-04,  3.16705205e-04,  3.88904999e-04,\n",
       "              4.54840447e-05,  5.91023709e-04,  6.25175657e-04,  2.00764480e-04,\n",
       "             -4.44656598e-06,  3.45970097e-04,  2.75200705e-06,  1.75962967e-04,\n",
       "              1.78287319e-05, -9.75808798e-05,  4.16980853e-04, -4.51737469e-05],\n",
       "            dtype=float32),\n",
       "      array([[-0.00504901, -0.00512556,  0.00810251, ...,  0.00058395,\n",
       "              -0.00045261,  0.00125068],\n",
       "             [ 0.00653004,  0.00763137,  0.00913188, ...,  0.00493922,\n",
       "              -0.00371219,  0.00109413],\n",
       "             [ 0.00123618, -0.00377357,  0.00874265, ..., -0.00150152,\n",
       "              -0.00670447, -0.00394049],\n",
       "             ...,\n",
       "             [ 0.00766841,  0.003002  ,  0.00795839, ...,  0.00558634,\n",
       "              -0.00017542, -0.00755993],\n",
       "             [-0.00342624,  0.00071168,  0.00485548, ...,  0.00745182,\n",
       "               0.00573975, -0.00352333],\n",
       "             [ 0.0081714 , -0.00102672,  0.00168998, ...,  0.00804382,\n",
       "               0.00869627, -0.00838723]], dtype=float32),\n",
       "      array([-3.38352314e-04, -2.48363067e-04,  8.63820023e-05, -1.92222287e-04,\n",
       "              6.90580782e-05, -3.07518530e-05, -2.26938238e-04, -2.21442635e-04,\n",
       "              1.52152934e-04,  1.73171327e-04,  1.93541215e-04, -1.72122556e-04,\n",
       "              2.01518589e-04, -4.32179397e-04,  1.12696871e-04, -1.71132720e-04,\n",
       "              8.35516912e-05,  2.81483255e-04, -2.25795433e-04, -1.32268193e-04,\n",
       "              1.79934825e-04,  5.29820609e-05, -7.80739065e-05,  1.33333524e-04,\n",
       "             -9.91307606e-05,  7.93267754e-05, -2.40744004e-04,  6.18096892e-05,\n",
       "              3.20429361e-04,  4.47339960e-04,  3.00936863e-05,  2.02335752e-04,\n",
       "              8.94426121e-05, -1.48620325e-04,  1.65880396e-04,  9.51500915e-05,\n",
       "              1.52512366e-04, -3.85794410e-05, -1.08860360e-04, -5.06978176e-05,\n",
       "              8.85751215e-05, -3.76539283e-05, -2.51995607e-05, -2.04336233e-04,\n",
       "              1.49084968e-04, -1.77159673e-04,  3.44248838e-04,  7.82555435e-05,\n",
       "              1.02692618e-04, -2.13150761e-05, -8.88534487e-05,  1.07394779e-04,\n",
       "             -1.88755817e-04,  3.01448395e-04,  5.46428055e-05, -2.69940065e-05,\n",
       "              1.75569876e-05, -2.52065773e-04, -7.66584606e-07,  3.04935442e-04,\n",
       "              1.40586984e-04, -1.91928761e-04,  1.10853383e-04,  1.19678079e-04,\n",
       "              3.25442932e-04,  1.34715578e-04,  4.96932844e-05, -1.91091807e-04,\n",
       "             -4.35009133e-04, -3.43914551e-04,  1.30536340e-04,  1.75431400e-04,\n",
       "             -1.54582813e-04, -1.53899426e-04, -2.03277261e-04, -2.50884827e-04,\n",
       "             -1.36372197e-04,  3.25157802e-04,  4.77641472e-04, -2.56072090e-04,\n",
       "              1.36641378e-04,  1.16763977e-05, -2.20085305e-04, -3.22722917e-04,\n",
       "             -1.78305403e-04,  1.79142211e-04, -1.57667309e-04,  4.01095167e-05,\n",
       "              4.77149624e-05,  1.06017163e-04,  6.91110472e-05, -1.28190193e-04,\n",
       "             -1.22633268e-04, -4.66613528e-06, -3.17280428e-05, -4.49539453e-04,\n",
       "             -1.84289398e-04,  1.33987078e-05, -1.34102811e-04,  1.25730439e-04,\n",
       "             -3.23495915e-04, -3.48232134e-05,  8.59286447e-05,  1.46438484e-04,\n",
       "              1.80435600e-04, -1.26264596e-04,  1.04953528e-04, -1.02030157e-04,\n",
       "              1.81537544e-04, -6.66315391e-05, -1.36169838e-04, -7.11715693e-05,\n",
       "             -9.35960925e-05, -1.25315448e-04, -1.08828666e-04, -1.97452537e-04,\n",
       "              1.80089730e-04, -1.62215860e-04,  3.33582517e-04,  1.85059631e-04,\n",
       "              2.21994502e-04,  4.26416402e-04,  5.92126125e-05, -1.84243676e-04,\n",
       "              6.31344665e-05, -2.20820817e-04,  3.59388941e-05, -4.97126093e-05],\n",
       "            dtype=float32)),),\n",
       "    ()),\n",
       "   (),\n",
       "   ()),\n",
       "  {'__marker_for_cached_weights_': ()}),\n",
       " (((), (((), ((), ())), ((), ()), ()), (), ()),\n",
       "  {'__marker_for_cached_state_': ()}))"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2=Siamese()\n",
    "model2.init_from_file('./model2/model.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "5640b21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.5764\n"
     ]
    }
   ],
   "source": [
    "accuracy = test(S1_test,S2_test, y_test, 0.7, model2, vocab, batch_size = 500) \n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "id": "22c56c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8709724"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"他很好\",\"他非常好\",model2,vocab,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "9c6d5a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8197402"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"他很好\",\"他很出色\",model2,vocab,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "d8bb2c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74816334"
      ]
     },
     "execution_count": 679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"怎样修改号码\",\"如何修改号码\",model2,vocab,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "6527e544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6986873"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"怎样修改号码\",\"怎样改变号码\",model2,vocab,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "c6c9d13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step      1: Total number of trainable weights: 816128\n",
      "Step      1: Ran 1 train steps in 5.03 secs\n",
      "Step      1: train TripletLoss |  0.50999707\n",
      "Step      1: eval  TripletLoss |  0.50219840\n",
      "\n",
      "Step    100: Ran 99 train steps in 35.32 secs\n",
      "Step    100: train TripletLoss |  0.50474632\n",
      "Step    100: eval  TripletLoss |  0.50047755\n",
      "\n",
      "Step    200: Ran 100 train steps in 47.82 secs\n",
      "Step    200: train TripletLoss |  0.47630322\n",
      "Step    200: eval  TripletLoss |  0.57024050\n",
      "\n",
      "Step    300: Ran 100 train steps in 66.41 secs\n",
      "Step    300: train TripletLoss |  0.13668355\n",
      "Step    300: eval  TripletLoss |  0.75268292\n",
      "\n",
      "Step    400: Ran 100 train steps in 74.59 secs\n",
      "Step    400: train TripletLoss |  0.06465720\n",
      "Step    400: eval  TripletLoss |  0.73997897\n"
     ]
    }
   ],
   "source": [
    "train_steps = 400\n",
    "training_loop = train_model(lr_schedule,output_dir='model4/')\n",
    "training_loop.run(train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "76d10d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((array([[-0.09432655,  0.08404654, -0.10992641, ...,  0.10568206,\n",
       "            0.04466164, -0.01650544],\n",
       "          [-0.02112508,  0.00744944, -0.10839731, ..., -0.03950041,\n",
       "            0.1107209 , -0.00784869],\n",
       "          [ 0.0776218 ,  0.11937916, -0.08957   , ...,  0.14807346,\n",
       "            0.13952583, -0.13035005],\n",
       "          ...,\n",
       "          [ 0.11588665, -0.08656292,  0.1343638 , ..., -0.09316377,\n",
       "           -0.03025847, -0.13725436],\n",
       "          [-0.10751566,  0.11157978,  0.10652941, ..., -0.07987989,\n",
       "           -0.12822305,  0.02550771],\n",
       "          [-0.09746387,  0.12430809, -0.07781336, ...,  0.01707025,\n",
       "           -0.09733935,  0.13684593]], dtype=float32),\n",
       "   (((), ((), ())),\n",
       "    ((array([[ 0.00948785,  0.00025126, -0.00730977, ...,  0.01080846,\n",
       "              -0.00014758,  0.00044009],\n",
       "             [-0.00745586,  0.00868924, -0.00682038, ...,  0.00601123,\n",
       "               0.00183884, -0.00259202],\n",
       "             [-0.00239765, -0.00643752, -0.00682915, ...,  0.01017619,\n",
       "               0.01170445, -0.0011879 ],\n",
       "             ...,\n",
       "             [ 0.00307855, -0.01217455, -0.00862269, ..., -0.00220587,\n",
       "               0.00627426,  0.01423031],\n",
       "             [ 0.01323261,  0.00120642,  0.0006507 , ..., -0.00580647,\n",
       "              -0.01270153, -0.00406616],\n",
       "             [-0.00244187, -0.0023275 , -0.00457131, ..., -0.00537078,\n",
       "               0.00583808, -0.02202621]], dtype=float32),\n",
       "      array([ 1.1831980e-03,  1.4503425e-03,  1.2122696e-03,  6.3146319e-04,\n",
       "              6.4262585e-04,  9.9514215e-04,  6.4748741e-04,  7.1551581e-04,\n",
       "              1.3073384e-03,  5.3767947e-04,  6.6867465e-04,  1.3982467e-03,\n",
       "              8.3390286e-04,  1.4336078e-03,  1.5721376e-03,  1.0656198e-03,\n",
       "              1.4671648e-03,  6.5498758e-04,  3.6629621e-04,  6.4792606e-04,\n",
       "              1.0802859e-03,  8.4527372e-04,  1.1575569e-03,  1.4363222e-03,\n",
       "              9.0933632e-04,  1.1063979e-03,  4.5550798e-04,  9.2894415e-04,\n",
       "              1.4149123e-03,  1.4500627e-03,  1.3330678e-03,  9.2504709e-04,\n",
       "              1.2122213e-03,  1.6657106e-03,  1.0975386e-03,  1.4244913e-03,\n",
       "              7.3484250e-04,  1.1903824e-03,  8.7769958e-04,  1.1029616e-03,\n",
       "              1.2742245e-03,  9.7158516e-04,  1.1985416e-03,  9.5380074e-04,\n",
       "              1.4433704e-03,  1.2294389e-03,  1.1751619e-03,  1.3361573e-03,\n",
       "              1.2731318e-03,  9.0767170e-04,  1.2658357e-03,  1.2668596e-03,\n",
       "              9.5270260e-04,  1.3243500e-03,  1.0571685e-03,  1.0707532e-03,\n",
       "              1.3223520e-03,  9.6120487e-04,  1.1280846e-03,  1.2485778e-03,\n",
       "              1.3613554e-03,  4.2154721e-04,  9.5078012e-04,  1.3145785e-03,\n",
       "              1.7094144e-03,  1.8072965e-03,  8.2942680e-04,  3.9194617e-04,\n",
       "              1.6291811e-03,  1.5915642e-03,  9.1252924e-04,  6.6979765e-04,\n",
       "              1.3190287e-03,  1.2542614e-03,  1.5225221e-03,  6.2742369e-04,\n",
       "              1.4361952e-03,  1.3957378e-03,  1.3401599e-03,  8.6016604e-04,\n",
       "              1.0883043e-03,  1.0985136e-03,  1.5194790e-03,  1.3393696e-03,\n",
       "              1.1581855e-03,  1.3549069e-03,  1.2099074e-03,  1.3798475e-03,\n",
       "              1.0990218e-03,  6.9671066e-04,  1.3227514e-03,  1.0503707e-03,\n",
       "              1.2430357e-03,  8.2075800e-04,  9.8237582e-04,  1.1591826e-03,\n",
       "              4.8171476e-04,  1.3261909e-03,  1.7265282e-03,  8.9587155e-04,\n",
       "              9.0636517e-04,  5.2641530e-04,  9.0692716e-04,  8.9784065e-04,\n",
       "              4.9051398e-04,  7.2250684e-04,  1.2889900e-03,  1.0531466e-03,\n",
       "              1.0329066e-03,  1.1794065e-03,  2.7391643e-04,  1.1437557e-03,\n",
       "              1.2673527e-03,  7.8250724e-04,  1.3122667e-03,  1.3636627e-03,\n",
       "              8.5145538e-04,  1.6673116e-03,  1.0569865e-03,  1.1663045e-03,\n",
       "              3.3437141e-04,  9.5052645e-04,  9.2924404e-04,  1.1526927e-03,\n",
       "              8.6313952e-04,  3.8358843e-04,  1.2428401e-03,  7.7747041e-04,\n",
       "              2.6816028e-04, -8.4006504e-05,  2.9351524e-04,  5.0891057e-04,\n",
       "              1.7363136e-04, -1.5018458e-04,  5.1383028e-04,  5.9680251e-04,\n",
       "              7.1332332e-05,  4.8761081e-04,  5.1173783e-04,  4.5617018e-04,\n",
       "              3.3804323e-04, -1.4696631e-05,  6.7379198e-04,  8.4357988e-04,\n",
       "              2.7470637e-04,  5.8569317e-04,  1.7368866e-05,  3.2578793e-04,\n",
       "              3.3750714e-04,  3.9457707e-04,  6.4175582e-04, -3.5602637e-04,\n",
       "              4.9689692e-04,  4.1061544e-04, -1.1013921e-04,  9.2837773e-04,\n",
       "              2.9703975e-05,  1.5261861e-04,  4.2813941e-04,  2.4197249e-04,\n",
       "              4.5248860e-04,  1.7483464e-04,  1.2682752e-03,  1.2963733e-03,\n",
       "              4.7453234e-04,  1.4532682e-04,  4.6240770e-05,  2.2917743e-04,\n",
       "              2.5737038e-04,  1.2331843e-04,  8.7839738e-04,  4.4010399e-04,\n",
       "              2.1928010e-04,  2.6403836e-04,  6.0184579e-04,  6.7044038e-04,\n",
       "              2.6964978e-04,  6.2874658e-04,  6.2712934e-04,  4.8583371e-04,\n",
       "              5.1828555e-04,  7.6421531e-04,  9.2131970e-04, -1.0578173e-04,\n",
       "              3.9141663e-04,  3.3985666e-04,  4.4231690e-04,  3.2809633e-04,\n",
       "              6.3996646e-04,  3.6415306e-04,  3.4199649e-04,  5.9215480e-04,\n",
       "              1.4293251e-04,  9.6999208e-04,  1.2468448e-04,  3.5514076e-05,\n",
       "              9.2345098e-04,  8.3441054e-04,  5.7561457e-04,  5.9479976e-04,\n",
       "              7.1888900e-04,  3.4064695e-04,  5.0442328e-04, -2.0534849e-04,\n",
       "              6.5372931e-04,  9.6170377e-05,  3.1073025e-04,  2.9408431e-04,\n",
       "              6.3967864e-06, -3.0923933e-05,  2.5120599e-04,  4.6200896e-04,\n",
       "              1.6807308e-04,  1.2911147e-03,  2.0914475e-04,  7.5628556e-04,\n",
       "              7.0964108e-04,  7.2326494e-04,  3.2363116e-04,  8.4358465e-04,\n",
       "              4.1541985e-05,  5.9520453e-04,  5.7559257e-04,  3.3447042e-04,\n",
       "              5.7983963e-04,  2.9776976e-04,  2.2388894e-04,  2.0790473e-04,\n",
       "             -3.4268352e-04,  4.7753676e-04,  5.3101784e-04,  6.0590508e-04,\n",
       "              7.0906326e-04,  5.3881394e-04,  1.1999560e-04,  5.4658786e-04,\n",
       "              3.8811978e-04,  2.4812811e-04,  1.3479593e-04,  5.7230727e-04,\n",
       "              5.0367613e-04,  6.5317011e-04,  8.1695413e-04,  5.0167297e-04,\n",
       "             -1.0387073e-04,  6.4118381e-04,  9.3363773e-04,  6.5687386e-04,\n",
       "             -4.3822238e-05,  6.8767980e-04,  3.0632076e-04,  1.0081805e-04,\n",
       "              4.0928990e-05, -1.3667379e-04,  3.6160467e-04,  3.5307885e-04],\n",
       "            dtype=float32),\n",
       "      array([[-0.00522438, -0.00541647,  0.00826166, ...,  0.00046036,\n",
       "              -0.00039603,  0.00107715],\n",
       "             [ 0.00659839,  0.00710961,  0.00931091, ...,  0.00481712,\n",
       "              -0.00388773,  0.00104362],\n",
       "             [ 0.0012652 , -0.00380811,  0.00868185, ..., -0.00141653,\n",
       "              -0.00669883, -0.00391216],\n",
       "             ...,\n",
       "             [ 0.00718533,  0.00325922,  0.00794784, ...,  0.00682884,\n",
       "              -0.0008708 , -0.00707347],\n",
       "             [-0.00370898, -0.0005064 ,  0.00382763, ...,  0.0063121 ,\n",
       "               0.0043242 , -0.00351013],\n",
       "             [ 0.00704169, -0.00088968,  0.00157673, ...,  0.00888221,\n",
       "               0.00874485, -0.00760858]], dtype=float32),\n",
       "      array([-3.37517413e-04, -2.40458481e-04,  8.74054022e-05, -1.72908374e-04,\n",
       "              5.95321944e-05, -3.18515558e-05, -2.36088075e-04, -2.29713914e-04,\n",
       "              1.55567759e-04,  1.71752225e-04,  1.85735058e-04, -1.55127025e-04,\n",
       "              2.02321404e-04, -4.25918464e-04,  9.09159644e-05, -1.66167782e-04,\n",
       "              8.91925811e-05,  2.69172771e-04, -1.96254623e-04, -1.22461453e-04,\n",
       "              1.82952339e-04,  4.73660402e-05, -8.80275984e-05,  1.33108479e-04,\n",
       "             -9.51106922e-05,  8.41128203e-05, -2.39502187e-04,  7.65899094e-05,\n",
       "              3.18980456e-04,  4.33738984e-04,  4.55669506e-05,  2.14444692e-04,\n",
       "              8.56746337e-05, -1.40736476e-04,  1.81865806e-04,  9.47098961e-05,\n",
       "              1.54859430e-04, -3.87433975e-05, -9.82596248e-05, -4.20996366e-05,\n",
       "              9.77515592e-05, -3.85139938e-05, -3.01685432e-05, -2.14813612e-04,\n",
       "              1.47755098e-04, -1.65686215e-04,  3.57452314e-04,  9.03078617e-05,\n",
       "              9.55633150e-05, -4.60780166e-06, -9.87766689e-05,  1.15990282e-04,\n",
       "             -1.93164495e-04,  2.99212872e-04,  6.61506565e-05, -2.33298542e-05,\n",
       "              7.69775033e-06, -2.60914880e-04,  7.47778404e-06,  2.96451646e-04,\n",
       "              1.41046257e-04, -1.64204146e-04,  1.11644738e-04,  1.15146140e-04,\n",
       "              3.20957624e-04,  1.58591982e-04,  3.88761073e-05, -1.78301925e-04,\n",
       "             -4.26541897e-04, -3.43646185e-04,  1.16317402e-04,  1.64290250e-04,\n",
       "             -1.48065388e-04, -1.61588614e-04, -1.93816406e-04, -2.42538343e-04,\n",
       "             -1.17161486e-04,  3.15845828e-04,  4.58726281e-04, -2.59198045e-04,\n",
       "              1.39077340e-04,  1.18342050e-05, -2.22751652e-04, -3.08650342e-04,\n",
       "             -1.87660960e-04,  1.76992078e-04, -1.56861992e-04,  3.95580428e-05,\n",
       "              3.07935625e-05,  1.01872101e-04,  5.29995777e-05, -1.28481435e-04,\n",
       "             -1.19763536e-04,  1.42629478e-05, -2.92644709e-05, -4.35605849e-04,\n",
       "             -1.70613595e-04,  1.10875171e-05, -1.30969114e-04,  1.12014561e-04,\n",
       "             -3.08812800e-04, -4.21151926e-05,  9.36778961e-05,  1.40265722e-04,\n",
       "              1.77604627e-04, -1.31207198e-04,  1.21807621e-04, -8.79629879e-05,\n",
       "              1.87765690e-04, -5.48445460e-05, -1.34938193e-04, -6.20114733e-05,\n",
       "             -9.02524334e-05, -1.27514417e-04, -1.16995310e-04, -2.03265241e-04,\n",
       "              1.80308707e-04, -1.75148016e-04,  3.29613569e-04,  1.65299047e-04,\n",
       "              2.14172745e-04,  4.16671915e-04,  6.72561582e-05, -1.78440183e-04,\n",
       "              5.82319117e-05, -2.13717896e-04,  2.14184547e-05, -4.65818921e-05],\n",
       "            dtype=float32)),),\n",
       "    ()),\n",
       "   (),\n",
       "   ()),\n",
       "  {'__marker_for_cached_weights_': ()}),\n",
       " (((), (((), ((), ())), ((), ()), ()), (), ()),\n",
       "  {'__marker_for_cached_state_': ()}))"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4=Siamese()\n",
    "model4.init_from_file('./model4/model.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "dc47e22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.5652\n"
     ]
    }
   ],
   "source": [
    "accuracy = test(S1_test,S2_test, y_test, 0.7, model4, vocab, batch_size = 500) \n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "3cbbcfa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88383526"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"他很好\",\"他非常好\",model4,vocab,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "a72cb8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8027178"
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"他很好\",\"他很出色\",model4,vocab,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "0da5c271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7491411"
      ]
     },
     "execution_count": 682,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"怎样修改号码\",\"如何修改号码\",model4,vocab,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "id": "cfa5c47e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70876765"
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"怎样修改号码\",\"怎样改变号码\",model4,vocab,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa5c1c6",
   "metadata": {},
   "source": [
    "Based on the accuracy and predict result, I chose the first model I trained to implement the EQ of MT. Due to the time limit, I selected parallel zh-en coprus just with a few sentences and transalte by Google translate and use bleu, rouge and siamese to evaluate the MT quality respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0063830",
   "metadata": {},
   "source": [
    "# Google translate the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "29a65e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"news-commentary-v14.en-zh.tsv\",sep=\"\\t\",engine=\"python\",nrows=5,names=[\"source\",\"reference\"],dtype={\"source\":str(),\"reference\":str()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0580d0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                        1929年还是1989年?\n",
       "1    巴黎-随着经济危机不断加深和蔓延，整个世界一直在寻找历史上的类似事件希望有助于我们了解目前正...\n",
       "2    一开始，很多人把这次危机比作1982年或1973年所发生的情况，这样得类比是令人宽心的，因为...\n",
       "3    如今人们的心情却是沉重多了，许多人开始把这次危机与1929年和1931年相比，即使一些国家政...\n",
       "4               目前的趋势是，要么是过度的克制（欧洲 ） ， 要么是努力的扩展（美国 ） 。\n",
       "Name: reference, dtype: object"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"reference\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a6c05ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "source=df[\"source\"].values.tolist()\n",
    "reference=df[\"reference\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "da53dd74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1929年或1989年？',\n",
       " '巴黎-随着经济危机加深和扩大，世界一直在寻求历史模拟，以帮助我们了解发生了什么。',\n",
       " '在危机的开始时，很多人将它与1982年或1973年相比，这是令人放心的，因为这两个日期都指的是经典的周期性下滑。',\n",
       " '今天，这种情绪更加严峻，参考于1929年和1931年开始比比皆是，即使一些政府继续表现得好像危机比特殊的危机更加古典。',\n",
       " '趋势是过度克制（欧洲）或努力的扩散（美国）。']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google_trans_new import google_translator  \n",
    "translator = google_translator() \n",
    "google_translation=[]\n",
    "for i,sent in enumerate(source):\n",
    "    google_translation.append(translator.translate(sent,lang_tgt=\"zh-cn\").strip().replace(\" - \",\"-\"))\n",
    "    \n",
    "google_translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0f6ca0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1929年还是1989年?',\n",
       " '巴黎-随着经济危机不断加深和蔓延，整个世界一直在寻找历史上的类似事件希望有助于我们了解目前正在发生的情况。',\n",
       " '一开始，很多人把这次危机比作1982年或1973年所发生的情况，这样得类比是令人宽心的，因为这两段时期意味着典型的周期性衰退。',\n",
       " '如今人们的心情却是沉重多了，许多人开始把这次危机与1929年和1931年相比，即使一些国家政府的表现仍然似乎把视目前的情况为是典型的而看见的衰退。',\n",
       " '目前的趋势是，要么是过度的克制（欧洲 ） ， 要么是努力的扩展（美国 ） 。']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc06771",
   "metadata": {},
   "source": [
    "# Google translate with Bleu evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "136ca053",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.499 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "reference_token=[]\n",
    "google_translation_token=[]\n",
    "for sent1,sent2 in zip(reference,google_translation):\n",
    "    reference_token.append([\" \".join(jieba.cut(sent1, cut_all=False)).split()])\n",
    "    google_translation_token.append(\" \".join(jieba.cut(sent2, cut_all=False)).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "905768d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.29%\n",
      "7.93%\n",
      "26.51%\n"
     ]
    }
   ],
   "source": [
    "# Using bleu score to evaluate the MT quality.\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "score_bleu1=corpus_bleu(reference_token,google_translation_token,weights=[1,0,0,0]) # align different weights to differnet n-grams\n",
    "score_bleu2=corpus_bleu(reference_token,google_translation_token,weights=[0,2,0,0])\n",
    "score_bleu3=corpus_bleu(reference_token,google_translation_token,weights=[0.5,0.2,0.2,0.1])\n",
    "print(\"%.2f%%\"%(score_bleu*100))\n",
    "print(\"%.2f%%\"%(score_bleu2*100))\n",
    "print(\"%.2f%%\"%(score_bleu3*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da5434f",
   "metadata": {},
   "source": [
    "# Google translate with Rouge evalution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac0ae1e",
   "metadata": {},
   "source": [
    "ROUGE-1 refers to the overlap of unigram (each word) between the system and reference summaries.\n",
    "ROUGE-2 refers to the overlap of bigrams2 between the system and reference summaries.\n",
    "ROUGE-L: Longest Common Subsequence based statistics. Longest common subsequence problem takes into account sentence level structure similarity naturally and identifies longest co-occurring in sequence n-grams automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "758ec43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge-1': {'f': 0.6798418922507773, 'p': 0.7226890756302521, 'r': 0.6417910447761194}, 'rouge-2': {'f': 0.4266666617102223, 'p': 0.47058823529411764, 'r': 0.3902439024390244}, 'rouge-l': {'f': 0.6561264772310144, 'p': 0.6974789915966386, 'r': 0.6194029850746269}}\n"
     ]
    }
   ],
   "source": [
    "# from rouge_metric import PerlRouge\n",
    "# rouge=PerlRouge(rouge_n_max=3,rouge_l=True,rouge_w=True,rouge_w_weight=1.2,rouge_s=True,rouge_su=True,skip_gap=4)\n",
    "\n",
    "# translation_rouge=[\"\\n\".join(google_translation)]\n",
    "# referance_rouge=[[\"\\n\".join(reference)]]\n",
    "# score=rouge.evaluate(translation_rouge,referance_rouge)\n",
    "# print(score)\n",
    "# I tried to use rouge_metric, but it didnt work on the Chinese characters, so I chose another module\n",
    "import lawrouge\n",
    "translation_rouge=[\"\\n\".join(google_translation)]\n",
    "referance_rouge=[\"\\n\".join(reference)]\n",
    "rouge = lawrouge.Rouge(exclusive=True) # exclusive=True means the text is the collection of characters\n",
    "scores = rouge.get_scores(translation_rouge, referance_rouge, avg=1)# avg=1 means After splitting the two substrings passed by the user according to the sentence separator, the average Rouge value is returned.\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cca0a168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1929年或1989年？\\n巴黎 - 随着经济危机加深和扩大，世界一直在寻求历史模拟，以帮助我们了解发生了什么。\\n在危机的开始时，很多人将它与1982年或1973年相比，这是令人放心的，因为这两个日期都指的是经典的周期性下滑。\\n今天，这种情绪更加严峻，参考于1929年和1931年开始比比皆是，即使一些政府继续表现得好像危机比特殊的危机更加古典。\\n趋势是过度克制（欧洲）或努力的扩散（美国）。']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation_rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aec39110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1929年还是1989年?\\n巴黎-随着经济危机不断加深和蔓延，整个世界一直在寻找历史上的类似事件希望有助于我们了解目前正在发生的情况。\\n一开始，很多人把这次危机比作1982年或1973年所发生的情况，这样得类比是令人宽心的，因为这两段时期意味着典型的周期性衰退。\\n如今人们的心情却是沉重多了，许多人开始把这次危机与1929年和1931年相比，即使一些国家政府的表现仍然似乎把视目前的情况为是典型的而看见的衰退。\\n目前的趋势是，要么是过度的克制（欧洲 ） ， 要么是努力的扩展（美国 ） 。']]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "referance_rouge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a3525c",
   "metadata": {},
   "source": [
    "# Google translate with Siamese evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1388699",
   "metadata": {},
   "source": [
    "I used the model I trained to evaluate the MT quality，because my evaluation metric is by semantics, I chose to use averaged weight to calculate the overall score for all 5 sentences(hereby I assumed the longer the sentence is, the more semantics weight it will contribute to the whole corpus. The weight will be the length of each sentence divided by sum of lenghts of all sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "21802673",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_score=[]\n",
    "sent_length=[]\n",
    "for sent1,sent2 in zip(reference,google_translation):\n",
    "    sent_score.append(predict(sent1,sent2,model,vocab,verbose=True))\n",
    "    sent_length.append(len(sent2))\n",
    "weights=np.divide(sent_length,sum(sent_length))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "34675276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.80%\n"
     ]
    }
   ],
   "source": [
    "score_siamese=np.average(np.array(sent_score),weights=weights)\n",
    "print(\"%.2f%%\"%(score_siamese*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51aa5317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"news-commentary-v14.en-zh.tsv\",sep=\"\\t\",engine=\"python\",nrows=5,names=[\"source\",\"reference\"],dtype={\"source\":str(),\"reference\":str()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "483dfe28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                        1929年还是1989年?\n",
       "1    巴黎-随着经济危机不断加深和蔓延，整个世界一直在寻找历史上的类似事件希望有助于我们了解目前正...\n",
       "2    一开始，很多人把这次危机比作1982年或1973年所发生的情况，这样得类比是令人宽心的，因为...\n",
       "3    如今人们的心情却是沉重多了，许多人开始把这次危机与1929年和1931年相比，即使一些国家政...\n",
       "4               目前的趋势是，要么是过度的克制（欧洲 ） ， 要么是努力的扩展（美国 ） 。\n",
       "Name: reference, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"reference\"].replace(\"1929\",\"o0000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7bf7ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                        1929 or 1989?\n",
      "1    PARIS – As the economic crisis deepens and wid...\n",
      "2    At the start of the crisis, many people likene...\n",
      "3    Today, the mood is much grimmer, with referenc...\n",
      "4    The tendency is either excessive restraint (Eu...\n",
      "Name: source, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66372b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"reference\"]=df[\"reference\"].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afad1f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                        1929年还是1989年?\n",
       "1    巴黎-随着经济危机不断加深和蔓延，整个世界一直在寻找历史上的类似事件希望有助于我们了解目前正...\n",
       "2    一开始，很多人把这次危机比作1982年或1973年所发生的情况，这样得类比是令人宽心的，因为...\n",
       "3    如今人们的心情却是沉重多了，许多人开始把这次危机与1929年和1931年相比，即使一些国家政...\n",
       "4               目前的趋势是，要么是过度的克制（欧洲 ） ， 要么是努力的扩展（美国 ） 。\n",
       "Name: reference, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"reference\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20327cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1071, 1131,   53],\n",
       "       [4259, 4802,  405],\n",
       "       [2052,  755,    0],\n",
       "       [ 910, 1039,    0],\n",
       "       [   0, 1201,  104],\n",
       "       [ 861,   10,  105],\n",
       "       [ 208,   78,    0],\n",
       "       [   1,  959,    0],\n",
       "       [   1,   14,  133],\n",
       "       [   1,  473,    1],\n",
       "       [   1, 3366,    1],\n",
       "       [   1, 1938,    1],\n",
       "       [   1,   74,    1],\n",
       "       [   1,    1,    1],\n",
       "       [   1,    1,    1],\n",
       "       [   1,    1,    1]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3deb505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 910, 2397,  755, 1039, 1938,  171,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1],\n",
       "       [1071, 4259,  281,   33, 2231, 1015, 1001,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1],\n",
       "       [ 473, 2143, 1358,   19,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0076aef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13825631, 16525303,  1238662],\n",
       "       [20974896, 24683947,  2120397],\n",
       "       [12438604, 11878796,   893333]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(batch1,batch2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b89273",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
